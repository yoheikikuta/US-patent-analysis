{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 234 (delta 1), reused 3 (delta 1), pack-reused 230\u001b[K\n",
      "Receiving objects: 100% (234/234), 152.83 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (133/133), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b docker https://github.com/yoheikikuta/bert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md\t\t    modeling.py\t\t  run_pretraining.py\r\n",
      "Dockerfile\t\t    modeling_test.py\t  run_squad.py\r\n",
      "LICENSE\t\t\t    multilingual.md\t  sample_text.txt\r\n",
      "README.md\t\t    optimization.py\t  tokenization.py\r\n",
      "__init__.py\t\t    optimization_test.py  tokenization_test.py\r\n",
      "create_pretraining_data.py  requirements.txt\t  utils\r\n",
      "extract_features.py\t    run_classifier.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow>=1.11.0 (from -r ./bert/requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/ad/48395de38c1e07bab85fc3bbec045e11ae49c02a4db0100463dd96031947/tensorflow-1.12.0-cp35-cp35m-manylinux1_x86_64.whl (83.1MB)\n",
      "\u001b[K    100% |################################| 83.1MB 14kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): termcolor>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): protobuf>=3.6.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): astor>=0.6.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): gast>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/d0/65fe48383146199f16dbd5999ef226b87bce63ad5cd73c840cf722637969/tensorboard-1.12.0-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |################################| 3.1MB 447kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |################################| 51kB 10.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): absl-py>=0.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.6.1->tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.11.0->-r ./bert/requirements.txt (line 1))\n",
      "Installing collected packages: keras-preprocessing, tensorboard, keras-applications, tensorflow\n",
      "  Found existing installation: Keras-Preprocessing 1.0.2\n",
      "    Uninstalling Keras-Preprocessing-1.0.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.0.2\n",
      "  Found existing installation: tensorboard 1.10.0\n",
      "    Uninstalling tensorboard-1.10.0:\n",
      "      Successfully uninstalled tensorboard-1.10.0\n",
      "  Found existing installation: Keras-Applications 1.0.4\n",
      "    Uninstalling Keras-Applications-1.0.4:\n",
      "      Successfully uninstalled Keras-Applications-1.0.4\n",
      "  Found existing installation: tensorflow 1.10.1\n",
      "    Uninstalling tensorflow-1.10.1:\n",
      "      Successfully uninstalled tensorflow-1.10.1\n",
      "Successfully installed keras-applications-1.0.6 keras-preprocessing-1.0.5 tensorboard-1.12.0 tensorflow-1.12.0\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ./bert/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and data download\n",
    "\n",
    "We solve RTE task in GLUE datasets; see https://www.nyu.edu/projects/bowman/glue.pdf in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./bert/model\", exist_ok=True)\n",
    "os.makedirs(\"./bert/data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-18 03:53:02--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.24.144, 2404:6800:4004:81b::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.24.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: './bert/model/uncased_L-12_H-768_A-12.zip'\n",
      "\n",
      "./bert/model/uncase 100%[===================>] 388.84M  52.0MB/s    in 10s     \n",
      "\n",
      "2018-11-18 03:53:12 (37.8 MB/s) - './bert/model/uncased_L-12_H-768_A-12.zip' saved [407727028/407727028]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ./bert/model/uncased_L-12_H-768_A-12.zip https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./bert/model/uncased_L-12_H-768_A-12.zip\n",
      "   creating: ./bert/model/uncased_L-12_H-768_A-12/\n",
      "  inflating: ./bert/model/uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: ./bert/model/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: ./bert/model/uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: ./bert/model/uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: ./bert/model/uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./bert/model/uncased_L-12_H-768_A-12.zip -d ./bert/model/ && \\\n",
    "  rm ./bert/model/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting MNLI...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "!python3 ./bert/utils/download_glue_data.py --data_dir ./bert/data --tasks RTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine-tuning\n",
    "\n",
    "It takes about 3 hours in a `n1-standard-4` instance on GCP Compute Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb2b92e7950>) includes params argument, but params are not passed to Estimator.\r\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_train_distribute': None, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_keep_checkpoint_max': 5, '_is_chief': True, '_model_dir': './bert/tmp/rte_output/', '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_task_id': 0, '_log_step_count_steps': None, '_protocol': None, '_cluster': None, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\r\n",
      "graph_options {\r\n",
      "  rewrite_options {\r\n",
      "    meta_optimizer_iterations: ONE\r\n",
      "  }\r\n",
      "}\r\n",
      ", '_device_fn': None, '_save_checkpoints_steps': 1000, '_task_type': 'worker', '_master': '', '_tf_random_seed': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb2b93e50f0>, '_save_checkpoints_secs': None, '_eval_distribute': None, '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': ''}\r\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\r\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\r\n",
      "INFO:tensorflow:Writing example 0 of 2490\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: train-0\r\n",
      "INFO:tensorflow:tokens: [CLS] no weapons of mass destruction found in iraq yet . [SEP] weapons of mass destruction found in iraq . [SEP]\r\n",
      "INFO:tensorflow:input_ids: 101 2053 4255 1997 3742 6215 2179 1999 5712 2664 1012 102 4255 1997 3742 6215 2179 1999 5712 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: not_entailment (id = 0)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: train-1\r\n",
      "INFO:tensorflow:tokens: [CLS] a place of sorrow , after pope john paul ii died , became a place of celebration , as roman catholic faithful gathered in downtown chicago to mark the installation of new pope benedict xvi . [SEP] pope benedict xvi is the new leader of the roman catholic church . [SEP]\r\n",
      "INFO:tensorflow:input_ids: 101 1037 2173 1997 14038 1010 2044 4831 2198 2703 2462 2351 1010 2150 1037 2173 1997 7401 1010 2004 3142 3234 11633 5935 1999 5116 3190 2000 2928 1996 8272 1997 2047 4831 12122 16855 1012 102 4831 12122 16855 2003 1996 2047 3003 1997 1996 3142 3234 2277 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: entailment (id = 1)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: train-2\r\n",
      "INFO:tensorflow:tokens: [CLS] her ##ce ##pt ##in was already approved to treat the sick ##est breast cancer patients , and the company said , monday , it will discuss with federal regulators the possibility of pre ##sc ##ri ##bing the drug for more breast cancer patients . [SEP] her ##ce ##pt ##in can be used to treat breast cancer . [SEP]\r\n",
      "INFO:tensorflow:input_ids: 101 2014 3401 13876 2378 2001 2525 4844 2000 7438 1996 5305 4355 7388 4456 5022 1010 1998 1996 2194 2056 1010 6928 1010 2009 2097 6848 2007 2976 25644 1996 6061 1997 3653 11020 3089 10472 1996 4319 2005 2062 7388 4456 5022 1012 102 2014 3401 13876 2378 2064 2022 2109 2000 7438 7388 4456 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: entailment (id = 1)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: train-3\r\n",
      "INFO:tensorflow:tokens: [CLS] ju ##die vivian , chief executive at prom ##ed ##ica , a medical service company that helps sustain the 2 - year - old vietnam heart institute in ho chi minh city ( formerly saigon ) , said that so far about 1 , 500 children have received treatment . [SEP] the previous name of ho chi minh city was saigon . [SEP]\r\n",
      "INFO:tensorflow:input_ids: 101 18414 10265 13801 1010 2708 3237 2012 20877 2098 5555 1010 1037 2966 2326 2194 2008 7126 15770 1996 1016 1011 2095 1011 2214 5148 2540 2820 1999 7570 9610 19538 2103 1006 3839 24001 1007 1010 2056 2008 2061 2521 2055 1015 1010 3156 2336 2031 2363 3949 1012 102 1996 3025 2171 1997 7570 9610 19538 2103 2001 24001 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: entailment (id = 1)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: train-4\r\n",
      "INFO:tensorflow:tokens: [CLS] a man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on bbc one ' s crime ##watch . cole ##tte ara ##m , 16 , was walking to her boyfriend ' s house in key ##worth , nottinghamshire , on 30 october 1983 when she disappeared . her body was later found in a field close to her home . paul stewart hutchinson , 50 , has been charged with murder and is due before nottingham magistrates later . [SEP] paul stewart hutchinson is accused of having stabbed a girl . [SEP]\r\n",
      "INFO:tensorflow:input_ids: 101 1037 2158 2003 2349 1999 2457 2101 5338 2007 1996 4028 2656 2086 3283 1997 1037 10563 3005 2553 2001 1996 2034 2000 2022 2956 2006 4035 2028 1005 1055 4126 18866 1012 5624 4674 19027 2213 1010 2385 1010 2001 3788 2000 2014 6898 1005 1055 2160 1999 3145 5172 1010 20126 1010 2006 2382 2255 3172 2043 2016 5419 1012 2014 2303 2001 2101 2179 1999 1037 2492 2485 2000 2014 2188 1012 2703 5954 17165 1010 2753 1010 2038 2042 5338 2007 4028 1998 2003 2349 2077 11331 23007 2101 1012 102 2703 5954 17165 2003 5496 1997 2383 13263 1037 2611 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: not_entailment (id = 0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 2490\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 233\n",
      "WARNING:tensorflow:From ./bert/run_classifier.py:557: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (32, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (32, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (32, 128)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-11-18 08:07:59.343665: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert/tmp/rte_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0230017\n",
      "INFO:tensorflow:examples/sec: 0.736054\n",
      "INFO:tensorflow:global_step/sec: 0.0230105\n",
      "INFO:tensorflow:examples/sec: 0.736337\n",
      "INFO:tensorflow:Saving checkpoints for 233 into ./bert/tmp/rte_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.31156892.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:Writing example 0 of 277\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-0\n",
      "INFO:tensorflow:tokens: [CLS] dana reeve , the widow of the actor christopher reeve , has died of lung cancer at age 44 , according to the christopher reeve foundation . [SEP] christopher reeve had an accident . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 11271 20726 1010 1996 7794 1997 1996 3364 5696 20726 1010 2038 2351 1997 11192 4456 2012 2287 4008 1010 2429 2000 1996 5696 20726 3192 1012 102 5696 20726 2018 2019 4926 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: not_entailment (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-1\n",
      "INFO:tensorflow:tokens: [CLS] yet , we now are discovering that antibiotics are losing their effectiveness against illness . disease - causing bacteria are mu ##tat ##ing faster than we can come up with new antibiotics to fight the new variations . [SEP] bacteria is winning the war against antibiotics . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2664 1010 2057 2085 2024 13648 2008 24479 2024 3974 2037 12353 2114 7355 1012 4295 1011 4786 10327 2024 14163 29336 2075 5514 2084 2057 2064 2272 2039 2007 2047 24479 2000 2954 1996 2047 8358 1012 102 10327 2003 3045 1996 2162 2114 24479 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: entailment (id = 1)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-2\n",
      "INFO:tensorflow:tokens: [CLS] cairo is now home to some 15 million people - a bu ##rgeon ##ing population that produces approximately 10 , 000 tonnes of rubbish per day , putting an enormous strain on public services . in the past 10 years , the government has tried hard to encourage private investment in the refuse sector , but some estimate 4 , 000 tonnes of waste is left behind every day , fest ##ering in the heat as it waits for someone to clear it up . it is often the people in the poor ##est neighbourhoods that are worst affected . but in some areas they are fighting back . in shu ##bra , one [SEP] 15 million tonnes of rubbish are produced daily in cairo . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 11096 2003 2085 2188 2000 2070 2321 2454 2111 1011 1037 20934 28242 2075 2313 2008 7137 3155 2184 1010 2199 11000 1997 29132 2566 2154 1010 5128 2019 8216 10178 2006 2270 2578 1012 1999 1996 2627 2184 2086 1010 1996 2231 2038 2699 2524 2000 8627 2797 5211 1999 1996 10214 4753 1010 2021 2070 10197 1018 1010 2199 11000 1997 5949 2003 2187 2369 2296 2154 1010 17037 7999 1999 1996 3684 2004 2009 18074 2005 2619 2000 3154 2009 2039 1012 2009 2003 2411 1996 2111 1999 1996 3532 4355 27535 2008 2024 5409 5360 1012 2021 1999 2070 2752 2027 2024 3554 2067 1012 1999 18454 10024 1010 2028 102 2321 2454 11000 1997 29132 2024 2550 3679 1999 11096 1012 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:label: not_entailment (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-3\n",
      "INFO:tensorflow:tokens: [CLS] the ami ##sh community in pennsylvania , which numbers about 55 , 000 , lives an agrarian lifestyle , shu ##nni ##ng technological advances like electricity and automobiles . and many say their ins ##ular lifestyle gives them a sense that they are protected from the violence of american society . but as residents gathered near the school , some wearing traditional ga ##rb and arriving in horse - drawn bug ##gies , they said that sense of safety had been shattered . \" if someone snaps and wants to do something stupid , there ' s no distance that ' s going to stop them , \" said jake king , [SEP] pennsylvania has the biggest ami ##sh community in the u . s . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1996 26445 4095 2451 1999 3552 1010 2029 3616 2055 4583 1010 2199 1010 3268 2019 23226 9580 1010 18454 23500 3070 10660 9849 2066 6451 1998 19207 1012 1998 2116 2360 2037 16021 7934 9580 3957 2068 1037 3168 2008 2027 2024 5123 2013 1996 4808 1997 2137 2554 1012 2021 2004 3901 5935 2379 1996 2082 1010 2070 4147 3151 11721 15185 1998 7194 1999 3586 1011 4567 11829 17252 1010 2027 2056 2008 3168 1997 3808 2018 2042 10909 1012 1000 2065 2619 20057 1998 4122 2000 2079 2242 5236 1010 2045 1005 1055 2053 3292 2008 1005 1055 2183 2000 2644 2068 1010 1000 2056 5180 2332 1010 102 3552 2038 1996 5221 26445 4095 2451 1999 1996 1057 1012 1055 1012 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:label: not_entailment (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-4\n",
      "INFO:tensorflow:tokens: [CLS] security forces were on high alert after an election campaign in which more than 1 , 000 people , including seven election candidates , have been killed . [SEP] security forces were on high alert after a campaign marred by violence . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 3036 2749 2020 2006 2152 9499 2044 2019 2602 3049 1999 2029 2062 2084 1015 1010 2199 2111 1010 2164 2698 2602 5347 1010 2031 2042 2730 1012 102 3036 2749 2020 2006 2152 9499 2044 1037 3049 24563 2011 4808 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: entailment (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 277\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-18-10:57:23\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./bert/tmp/rte_output/model.ckpt-233\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-18-10:59:45\n",
      "INFO:tensorflow:Saving dict for global step 233: eval_accuracy = 0.6931408, eval_loss = 0.71709377, global_step = 233, loss = 0.71939987\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 233: ./bert/tmp/rte_output/model.ckpt-233\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_accuracy = 0.6931408\n",
      "INFO:tensorflow:  eval_loss = 0.71709377\n",
      "INFO:tensorflow:  global_step = 233\n",
      "INFO:tensorflow:  loss = 0.71939987\n",
      "CPU times: user 4min 30s, sys: 33.3 s, total: 5min 4s\n",
      "Wall time: 2h 52min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python3 ./bert/run_classifier.py \\\n",
    "  --task_name=RTE \\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=./bert/data/RTE \\\n",
    "  --vocab_file=./bert/model/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "  --bert_config_file=./bert/model/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "  --init_checkpoint=./bert/model/uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "  --max_seq_length=128 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=3.0 \\\n",
    "  --output_dir=./bert/tmp/rte_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data making for our patent data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_info_target = pd.read_pickle(\"../data/citations_info_2000.df.gz\")\n",
    "training_app_df = pd.read_pickle(\"../data/training_app_1000.df.gz\")\n",
    "testset_app_df = pd.read_pickle(\"../data/testset_app_1000.df.gz\")\n",
    "grants_target_df = pd.read_pickle(\"../data/grants_for_2000.df.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_fnm</th>\n",
       "      <th>citation_pat_pgpub_id</th>\n",
       "      <th>parsed</th>\n",
       "      <th>ifw_number</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_subtype</th>\n",
       "      <th>form892</th>\n",
       "      <th>form1449</th>\n",
       "      <th>citation_in_oa</th>\n",
       "      <th>...</th>\n",
       "      <th>rejection_103</th>\n",
       "      <th>rejection_112</th>\n",
       "      <th>rejection_dp</th>\n",
       "      <th>objection</th>\n",
       "      <th>allowed_claims</th>\n",
       "      <th>cite102_gt1</th>\n",
       "      <th>cite103_gt3</th>\n",
       "      <th>cite103_eq1</th>\n",
       "      <th>cite103_max</th>\n",
       "      <th>signature_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>7391316</td>\n",
       "      <td>7391316</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>6992580</td>\n",
       "      <td>6992580</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>6992580</td>\n",
       "      <td>6992580</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>7774833</td>\n",
       "      <td>7774833</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12282000</td>\n",
       "      <td>/work/data/apps/2009/ipa090312/F_1385.xml</td>\n",
       "      <td>7411209</td>\n",
       "      <td>7411209</td>\n",
       "      <td>G9LENRJ8PPOPPY5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                    app_fnm citation_pat_pgpub_id  \\\n",
       "0  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               7391316   \n",
       "1  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               6992580   \n",
       "2  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               6992580   \n",
       "3  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               7774833   \n",
       "4  12282000  /work/data/apps/2009/ipa090312/F_1385.xml               7411209   \n",
       "\n",
       "    parsed       ifw_number  action_type action_subtype  form892  form1449  \\\n",
       "0  7391316  H20LX5QGPXXIFW4        103.0              a        1         0   \n",
       "1  6992580  H20LX5QGPXXIFW4        102.0              a        1         1   \n",
       "2  6992580  H20LX5QGPXXIFW4        103.0              a        1         1   \n",
       "3  7774833  H20LX5QGPXXIFW4        103.0              a        1         1   \n",
       "4  7411209  G9LENRJ8PPOPPY5        102.0              a        0         1   \n",
       "\n",
       "   citation_in_oa      ...       rejection_103  rejection_112  rejection_dp  \\\n",
       "0               1      ...                   1              0             1   \n",
       "1               1      ...                   1              0             1   \n",
       "2               1      ...                   1              0             1   \n",
       "3               1      ...                   1              0             1   \n",
       "4               1      ...                   1              0             0   \n",
       "\n",
       "   objection allowed_claims cite102_gt1  cite103_gt3 cite103_eq1  cite103_max  \\\n",
       "0          0              0           0            0           1            2   \n",
       "1          0              0           0            0           1            2   \n",
       "2          0              0           0            0           1            2   \n",
       "3          0              0           0            0           1            2   \n",
       "4          0              0           1            0           1            1   \n",
       "\n",
       "  signature_type  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              3  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_info_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>xml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12515852</td>\n",
       "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12033424</td>\n",
       "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12402344</td>\n",
       "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12155425</td>\n",
       "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                                xml\n",
       "0  14222691  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
       "1  12515852  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
       "2  12033424  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
       "3  12402344  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
       "4  12155425  <us-patent-application lang=\"EN\" dtd-version=\"..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_app_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "CLAIM_PAT = re.compile(r'<claims[^>]*>(.*)</claims>',re.MULTILINE|re.DOTALL)\n",
    "TAG_PAT = re.compile(r\"<.*?>\")\n",
    "LB_PAT = re.compile(r'[\\t\\n\\r\\f\\v][\" \"]*')\n",
    "\n",
    "def whole_xml_to_claim_xml(whole):\n",
    "    mat = CLAIM_PAT.search(whole)\n",
    "    return mat.group(1)\n",
    "def whole_xml_to_claim(whole):\n",
    "    return TAG_PAT.sub(' ', whole_xml_to_claim_xml(whole))\n",
    "\n",
    "def remove_linebreak_from_claim(claim):\n",
    "    '''\n",
    "    Remove line break symbol \"\\n\" with space(s).\n",
    "    '''\n",
    "    return LB_PAT.sub('', claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_app_df[\"claim\"] = training_app_df[\"xml\"].map(whole_xml_to_claim).map(remove_linebreak_from_claim)\n",
    "testset_app_df[\"claim\"] = testset_app_df[\"xml\"].map(whole_xml_to_claim).map(remove_linebreak_from_claim)\n",
    "grants_target_df[\"claim\"] = grants_target_df[\"xml\"].map(whole_xml_to_claim).map(remove_linebreak_from_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 . A terminal comprising:an upper arm having a top surface for a mating area; a lower arm paralleled with the upper arm and having a bottom surface soldering area; and a connecting arm connected with the upper arm and the lower arm. 2 . The terminal as recited in  claim 1 , wherein the whole terminal is structured in a folded manner with a tiny gap therebetween in a vertical direction, and one of said upper arm and said lower arm forms a projection in said gap to abut against the other in a vertical direction. 3 . The terminal as recited in  claim 2 , wherein said one of the upper arm and the lower arm forms a recess corresponding to the projection in said vertical direction. 4 . The terminal as recited in  claim 1 , wherein the upper arm defines a convex plate formed on the top surface thereof and having a top surface, and the mating area is the top surface of the convex plate. 5 . The terminal as recited in  claim 4 , wherein the upper arm defines a recess in a bottom surface thereof corresponding to said convex plate in a vertical direction. 6 . The terminal as recited in  claim 1 , wherein the lower arm defines at least one through slot extending throughout top and bottom surfaces thereof 7 . The terminal as recited in  claim 6 , wherein at least one through slot comprise two through slots paralleled with each other and spaced apart with each other along a transversal direction. 8 . The terminal as recited in  claim 6 , wherein at least one through slot comprise two through slots spaced apart with each other along a front to rear direction. 9 . The terminal as recited in  claim 6 , wherein at least one through slot comprise two through slots formed on two lateral sides of the lower arm. 10 . The terminal as recited in  claim 1 , wherein the lower arm defines protrusions or grooves formed on the bottom surface thereof 11 . A terminal module comprising:a printed circuit board having a plurality of front and rear conductive pads; and a plurality of terminals soldered to the printed circuit board; wherein each of terminal comprises paralleled upper and lower arms and a connecting arm connected with the upper arm and the lower arm, the upper arm defines a contacting area on a top surface thereof, the lower arm defines a soldering area on a bottom surface thereof, the plurality of terminals are located on the plurality of corresponding front conductive pads, and the lower arms of the plurality of terminals are soldered to the plurality of corresponding front conductive pads. 12 . The terminal module as recited in  claim 10 , wherein the lower arm defines at least one through slots extending throughout top and bottom surfaces thereof 13 . The terminal module as recited in  claim 10 , wherein the lower arm defines at least one protrusion or groove formed on the bottom surface thereof 14 . The terminal module as recited in  claim 10 , wherein the lower arm defines a projection formed on a top surface thereof and attached to a bottom surface of the upper arm. 15 . The terminal module as recited in  claim 10 , wherein the terminal module further comprises an insulator molding on a connection between the plurality of terminals and the printed circuit board. 16 . A method of manufacturing a terminal module, comprising the steps of:providing a plurality of folding type terminals and a printed circuit board having a plurality of front conductive pads formed on a top surface and a front end thereof; applying a plurality of soldering pastes on corresponding front conductive pads of the printed circuit;. applying the plurality of terminals on the corresponding soldering pastes through a fixture; and soldering the plurality of terminals to the front conductive pads through hot-bar, or SMT(surface mount technology) or laser welding process. 17 . The method of manufacturing the terminal module as recited in  claim 15 , wherein further molding an insulator on a connection between the plurality of terminals and the printed circuit board. 18 . The method of manufacturing the terminal module as recited in  claim 15 , wherein the terminal comprises paralleled upper arm and lower arm and a curved connecting arm connected with the upper arm and the lower arm. 19 . The method of manufacturing the terminal module as recited in  claim 17 , wherein the lower arm defines a projection formed on a top surface thereof and attached to a bottom surface of the upper arm. 20 . The method of manufacturing the terminal module as recited in  claim 17 , wherein the terminals provided in first step are partially gold-plated on outer surface thereof or partially gold-stripping from the terminals which are entirely gold-plated on outer surface through laser-welding process. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_app_df[\"claim\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( str(training_app_df[\"claim\"][0]).split(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_fnm</th>\n",
       "      <th>citation_pat_pgpub_id</th>\n",
       "      <th>parsed</th>\n",
       "      <th>ifw_number</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_subtype</th>\n",
       "      <th>form892</th>\n",
       "      <th>form1449</th>\n",
       "      <th>citation_in_oa</th>\n",
       "      <th>...</th>\n",
       "      <th>rejection_103</th>\n",
       "      <th>rejection_112</th>\n",
       "      <th>rejection_dp</th>\n",
       "      <th>objection</th>\n",
       "      <th>allowed_claims</th>\n",
       "      <th>cite102_gt1</th>\n",
       "      <th>cite103_gt3</th>\n",
       "      <th>cite103_eq1</th>\n",
       "      <th>cite103_max</th>\n",
       "      <th>signature_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>7391316</td>\n",
       "      <td>7391316</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>6992580</td>\n",
       "      <td>6992580</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>6992580</td>\n",
       "      <td>6992580</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13371769</td>\n",
       "      <td>/work/data/apps/2012/ipa120607/F_2322.xml</td>\n",
       "      <td>7774833</td>\n",
       "      <td>7774833</td>\n",
       "      <td>H20LX5QGPXXIFW4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12282000</td>\n",
       "      <td>/work/data/apps/2009/ipa090312/F_1385.xml</td>\n",
       "      <td>7411209</td>\n",
       "      <td>7411209</td>\n",
       "      <td>G9LENRJ8PPOPPY5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                    app_fnm citation_pat_pgpub_id  \\\n",
       "0  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               7391316   \n",
       "1  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               6992580   \n",
       "2  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               6992580   \n",
       "3  13371769  /work/data/apps/2012/ipa120607/F_2322.xml               7774833   \n",
       "4  12282000  /work/data/apps/2009/ipa090312/F_1385.xml               7411209   \n",
       "\n",
       "    parsed       ifw_number  action_type action_subtype  form892  form1449  \\\n",
       "0  7391316  H20LX5QGPXXIFW4        103.0              a        1         0   \n",
       "1  6992580  H20LX5QGPXXIFW4        102.0              a        1         1   \n",
       "2  6992580  H20LX5QGPXXIFW4        103.0              a        1         1   \n",
       "3  7774833  H20LX5QGPXXIFW4        103.0              a        1         1   \n",
       "4  7411209  G9LENRJ8PPOPPY5        102.0              a        0         1   \n",
       "\n",
       "   citation_in_oa      ...       rejection_103  rejection_112  rejection_dp  \\\n",
       "0               1      ...                   1              0             1   \n",
       "1               1      ...                   1              0             1   \n",
       "2               1      ...                   1              0             1   \n",
       "3               1      ...                   1              0             1   \n",
       "4               1      ...                   1              0             0   \n",
       "\n",
       "   objection allowed_claims cite102_gt1  cite103_gt3 cite103_eq1  cite103_max  \\\n",
       "0          0              0           0            0           1            2   \n",
       "1          0              0           0            0           1            2   \n",
       "2          0              0           0            0           1            2   \n",
       "3          0              0           0            0           1            2   \n",
       "4          0              0           1            0           1            1   \n",
       "\n",
       "  signature_type  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              3  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_info_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev set in bert repository is corresponding to test set in our case.  \n",
    "dev set includes label information and will not be used in training.  \n",
    "(test set in bert does not inlude answer labels.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data creating procedure is the following:\n",
    "- connect app_id and cited grant number\n",
    "- get [app_id, claim, parsed]\n",
    "- drop duplicates (duplication can exist because of different action types, etc)\n",
    "- add cited label as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = pd.merge(training_app_df, citations_info_target, on='app_id')[['app_id', 'claim', 'parsed']]\n",
    "dev_data_for_bert = pd.merge(testset_app_df, citations_info_target, on='app_id')[['app_id', 'claim', 'parsed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8179692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8179692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8206188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8206188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8177561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                              claim   parsed\n",
       "0  14222691  1 . A terminal comprising:an upper arm having ...  8179692\n",
       "1  14222691  1 . A terminal comprising:an upper arm having ...  8179692\n",
       "2  14222691  1 . A terminal comprising:an upper arm having ...  8206188\n",
       "3  14222691  1 . A terminal comprising:an upper arm having ...  8206188\n",
       "4  14222691  1 . A terminal comprising:an upper arm having ...  8177561"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120\n",
      "2059\n"
     ]
    }
   ],
   "source": [
    "print( len(train_data_for_bert) )\n",
    "print( len(dev_data_for_bert) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = train_data_for_bert.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "dev_data_for_bert = dev_data_for_bert.drop_duplicates(keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n",
      "1251\n"
     ]
    }
   ],
   "source": [
    "print( len(train_data_for_bert) )\n",
    "print( len(dev_data_for_bert) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert['label'] = \"cited\"\n",
    "dev_data_for_bert['label'] = \"cited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>parsed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8179692</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8206188</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8177561</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12515852</td>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>7235710</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12033424</td>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>6950953</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                              claim   parsed  label\n",
       "0  14222691  1 . A terminal comprising:an upper arm having ...  8179692  cited\n",
       "1  14222691  1 . A terminal comprising:an upper arm having ...  8206188  cited\n",
       "2  14222691  1 . A terminal comprising:an upper arm having ...  8177561  cited\n",
       "3  12515852  1 . A method for increasing seed yield in plan...  7235710  cited\n",
       "4  12033424  1 . An image forming apparatus, comprising:an ...  6950953  cited"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = train_data_for_bert.merge(grants_target_df, how='inner', on='parsed')\n",
    "train_data_for_bert = train_data_for_bert.drop(\"xml\", axis=1)\n",
    "\n",
    "dev_data_for_bert = dev_data_for_bert.merge(grants_target_df, how='inner', on='parsed')\n",
    "dev_data_for_bert = dev_data_for_bert.drop(\"xml\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim_x</th>\n",
       "      <th>parsed</th>\n",
       "      <th>label</th>\n",
       "      <th>claim_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8179692</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A board, comprising:a board body; a first c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8206188</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A connector terminal curved from a strip-sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8177561</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A socket contact terminal for electrical co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12515852</td>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>7235710</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A method for expressing in a non-monocotyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12033424</td>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>6950953</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A multifunctional printer, comprising:a mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                            claim_x   parsed  \\\n",
       "0  14222691  1 . A terminal comprising:an upper arm having ...  8179692   \n",
       "1  14222691  1 . A terminal comprising:an upper arm having ...  8206188   \n",
       "2  14222691  1 . A terminal comprising:an upper arm having ...  8177561   \n",
       "3  12515852  1 . A method for increasing seed yield in plan...  7235710   \n",
       "4  12033424  1 . An image forming apparatus, comprising:an ...  6950953   \n",
       "\n",
       "   label                                            claim_y  \n",
       "0  cited  1. A board, comprising:a board body; a first c...  \n",
       "1  cited  1. A connector terminal curved from a strip-sh...  \n",
       "2  cited  1. A socket contact terminal for electrical co...  \n",
       "3  cited  1. A method for expressing in a non-monocotyle...  \n",
       "4  cited  1. A multifunctional printer, comprising:a mai...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_up_unsited_grants(df, app_id, n=1, random_state=23):\n",
    "    '''\n",
    "    Randomly pick up uncited grant pair to a given app_id for generating negative samples.\n",
    "    '''\n",
    "    n_rows = df[ df['app_id'] != app_id ].sample(n=n, random_state=random_state)\n",
    "    \n",
    "    return [n_rows['parsed'].values[0], \"not_cited\" ,n_rows['claim_y'].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "\n",
    "train_non_cited_data = pd.DataFrame([\n",
    "    [app_id, claimx] + pick_up_unsited_grants(train_data_for_bert, app_id, random_state=seed+idx)\n",
    "    for idx, (app_id, claimx)\n",
    "    in enumerate(zip(train_data_for_bert['app_id'], train_data_for_bert['claim_x']))\n",
    "])\n",
    "\n",
    "train_non_cited_data.columns = train_data_for_bert.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim_x</th>\n",
       "      <th>parsed</th>\n",
       "      <th>label</th>\n",
       "      <th>claim_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>7137410</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A mixing valve having an exterior cover, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>7419473</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A living body inspection apparatus comprisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>7789044</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A collapsible pet carrier comprising:a tubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12515852</td>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>7702451</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A programmable engines-start system compris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12033424</td>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>8133762</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A method of making a semiconductor device, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                            claim_x   parsed  \\\n",
       "0  14222691  1 . A terminal comprising:an upper arm having ...  7137410   \n",
       "1  14222691  1 . A terminal comprising:an upper arm having ...  7419473   \n",
       "2  14222691  1 . A terminal comprising:an upper arm having ...  7789044   \n",
       "3  12515852  1 . A method for increasing seed yield in plan...  7702451   \n",
       "4  12033424  1 . An image forming apparatus, comprising:an ...  8133762   \n",
       "\n",
       "       label                                            claim_y  \n",
       "0  not_cited  1. A mixing valve having an exterior cover, sa...  \n",
       "1  not_cited  1. A living body inspection apparatus comprisi...  \n",
       "2  not_cited  1. A collapsible pet carrier comprising:a tubu...  \n",
       "3  not_cited  1. A programmable engines-start system compris...  \n",
       "4  not_cited  1. A method of making a semiconductor device, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_non_cited_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "\n",
    "dev_non_cited_data = pd.DataFrame([\n",
    "    [app_id, claimx] + pick_up_unsited_grants(dev_data_for_bert, app_id, random_state=seed+idx)\n",
    "    for idx, (app_id, claimx)\n",
    "    in enumerate(zip(dev_data_for_bert['app_id'], dev_data_for_bert['claim_x']))\n",
    "])\n",
    "\n",
    "dev_non_cited_data.columns = dev_data_for_bert.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim_x</th>\n",
       "      <th>parsed</th>\n",
       "      <th>label</th>\n",
       "      <th>claim_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14307191</td>\n",
       "      <td>1 . A method to aggregate, filter, and share e...</td>\n",
       "      <td>7729924</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A virtual knowledge management system using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13137006</td>\n",
       "      <td>1 . A display apparatus, comprising:a position...</td>\n",
       "      <td>8058137</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A method of manufacturing a semiconductor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12741959</td>\n",
       "      <td>1 - 33 . (canceled) 34 . A compound comprising...</td>\n",
       "      <td>7124864</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A gas assist strut and coupling member for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643447</td>\n",
       "      <td>1 . A terminal fitting formed by bending an el...</td>\n",
       "      <td>6979130</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. A bearing device for rotatably receiving a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14200253</td>\n",
       "      <td>1 . A printer for printing a three-dimensional...</td>\n",
       "      <td>6915265</td>\n",
       "      <td>not_cited</td>\n",
       "      <td>1. An integrated health care system for collec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                            claim_x   parsed  \\\n",
       "0  14307191  1 . A method to aggregate, filter, and share e...  7729924   \n",
       "1  13137006  1 . A display apparatus, comprising:a position...  8058137   \n",
       "2  12741959  1 - 33 . (canceled) 34 . A compound comprising...  7124864   \n",
       "3  12643447  1 . A terminal fitting formed by bending an el...  6979130   \n",
       "4  14200253  1 . A printer for printing a three-dimensional...  6915265   \n",
       "\n",
       "       label                                            claim_y  \n",
       "0  not_cited  1. A virtual knowledge management system using...  \n",
       "1  not_cited  1. A method of manufacturing a semiconductor w...  \n",
       "2  not_cited  1. A gas assist strut and coupling member for ...  \n",
       "3  not_cited  1. A bearing device for rotatably receiving a ...  \n",
       "4  not_cited  1. An integrated health care system for collec...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_non_cited_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = pd.concat([train_data_for_bert, train_non_cited_data]).reset_index(drop=True)\n",
    "dev_data_for_bert = pd.concat([dev_data_for_bert, dev_non_cited_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>claim_x</th>\n",
       "      <th>parsed</th>\n",
       "      <th>label</th>\n",
       "      <th>claim_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8179692</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A board, comprising:a board body; a first c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8206188</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A connector terminal curved from a strip-sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222691</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>8177561</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A socket contact terminal for electrical co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12515852</td>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>7235710</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A method for expressing in a non-monocotyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12033424</td>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>6950953</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A multifunctional printer, comprising:a mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                                            claim_x   parsed  \\\n",
       "0  14222691  1 . A terminal comprising:an upper arm having ...  8179692   \n",
       "1  14222691  1 . A terminal comprising:an upper arm having ...  8206188   \n",
       "2  14222691  1 . A terminal comprising:an upper arm having ...  8177561   \n",
       "3  12515852  1 . A method for increasing seed yield in plan...  7235710   \n",
       "4  12033424  1 . An image forming apparatus, comprising:an ...  6950953   \n",
       "\n",
       "   label                                            claim_y  \n",
       "0  cited  1. A board, comprising:a board body; a first c...  \n",
       "1  cited  1. A connector terminal curved from a strip-sh...  \n",
       "2  cited  1. A socket contact terminal for electrical co...  \n",
       "3  cited  1. A method for expressing in a non-monocotyle...  \n",
       "4  cited  1. A multifunctional printer, comprising:a mai...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert['index'] = train_data_for_bert.index\n",
    "dev_data_for_bert['index'] = dev_data_for_bert.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = train_data_for_bert.drop(\"app_id\", axis=1)\n",
    "train_data_for_bert = train_data_for_bert.drop(\"parsed\", axis=1)\n",
    "\n",
    "dev_data_for_bert = dev_data_for_bert.drop(\"app_id\", axis=1)\n",
    "dev_data_for_bert = dev_data_for_bert.drop(\"parsed\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_x</th>\n",
       "      <th>label</th>\n",
       "      <th>claim_y</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A board, comprising:a board body; a first c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A connector terminal curved from a strip-sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A socket contact terminal for electrical co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A method for expressing in a non-monocotyle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>1. A multifunctional printer, comprising:a mai...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             claim_x  label  \\\n",
       "0  1 . A terminal comprising:an upper arm having ...  cited   \n",
       "1  1 . A terminal comprising:an upper arm having ...  cited   \n",
       "2  1 . A terminal comprising:an upper arm having ...  cited   \n",
       "3  1 . A method for increasing seed yield in plan...  cited   \n",
       "4  1 . An image forming apparatus, comprising:an ...  cited   \n",
       "\n",
       "                                             claim_y  index  \n",
       "0  1. A board, comprising:a board body; a first c...      0  \n",
       "1  1. A connector terminal curved from a strip-sh...      1  \n",
       "2  1. A socket contact terminal for electrical co...      2  \n",
       "3  1. A method for expressing in a non-monocotyle...      3  \n",
       "4  1. A multifunctional printer, comprising:a mai...      4  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = train_data_for_bert.loc[:, ['index', 'claim_x', 'claim_y', 'label']]\n",
    "dev_data_for_bert = dev_data_for_bert.loc[:, ['index', 'claim_x', 'claim_y', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert.columns = ['index', 'claim_app', 'claim_cited_grant', 'label']\n",
    "dev_data_for_bert.columns = ['index', 'claim_app', 'claim_cited_grant', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claim_app</th>\n",
       "      <th>claim_cited_grant</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>1. A board, comprising:a board body; a first c...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>1. A connector terminal curved from a strip-sh...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1 . A terminal comprising:an upper arm having ...</td>\n",
       "      <td>1. A socket contact terminal for electrical co...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 . A method for increasing seed yield in plan...</td>\n",
       "      <td>1. A method for expressing in a non-monocotyle...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1 . An image forming apparatus, comprising:an ...</td>\n",
       "      <td>1. A multifunctional printer, comprising:a mai...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          claim_app  \\\n",
       "0      0  1 . A terminal comprising:an upper arm having ...   \n",
       "1      1  1 . A terminal comprising:an upper arm having ...   \n",
       "2      2  1 . A terminal comprising:an upper arm having ...   \n",
       "3      3  1 . A method for increasing seed yield in plan...   \n",
       "4      4  1 . An image forming apparatus, comprising:an ...   \n",
       "\n",
       "                                   claim_cited_grant  label  \n",
       "0  1. A board, comprising:a board body; a first c...  cited  \n",
       "1  1. A connector terminal curved from a strip-sh...  cited  \n",
       "2  1. A socket contact terminal for electrical co...  cited  \n",
       "3  1. A method for expressing in a non-monocotyle...  cited  \n",
       "4  1. A multifunctional printer, comprising:a mai...  cited  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claim_app</th>\n",
       "      <th>claim_cited_grant</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 . A method to aggregate, filter, and share e...</td>\n",
       "      <td>1. A method for detecting moving objects with ...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 . A display apparatus, comprising:a position...</td>\n",
       "      <td>1. A viewpoint position detecting apparatus fo...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1 - 33 . (canceled) 34 . A compound comprising...</td>\n",
       "      <td>1. A double-stranded ribonucleic acid (dsRNA),...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 . A terminal fitting formed by bending an el...</td>\n",
       "      <td>1. A female terminal fitting comprising:a subs...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1 . A printer for printing a three-dimensional...</td>\n",
       "      <td>1. A method of generating an object assembled ...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          claim_app  \\\n",
       "0      0  1 . A method to aggregate, filter, and share e...   \n",
       "1      1  1 . A display apparatus, comprising:a position...   \n",
       "2      2  1 - 33 . (canceled) 34 . A compound comprising...   \n",
       "3      3  1 . A terminal fitting formed by bending an el...   \n",
       "4      4  1 . A printer for printing a three-dimensional...   \n",
       "\n",
       "                                   claim_cited_grant  label  \n",
       "0  1. A method for detecting moving objects with ...  cited  \n",
       "1  1. A viewpoint position detecting apparatus fo...  cited  \n",
       "2  1. A double-stranded ribonucleic acid (dsRNA),...  cited  \n",
       "3  1. A female terminal fitting comprising:a subs...  cited  \n",
       "4  1. A method of generating an object assembled ...  cited  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_for_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the result dataframe with tab separation.  \n",
    "Manually upload the dataests onto google cloud storege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change label name in order to match RTE datasets case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert['label'] = train_data_for_bert['label'].str.replace(\"not_cited\", \"not_entailment\")\n",
    "train_data_for_bert['label'] = train_data_for_bert['label'].str.replace(\"cited\", \"entailment\")\n",
    "\n",
    "dev_data_for_bert['label'] = dev_data_for_bert['label'].str.replace(\"not_cited\", \"not_entailment\")\n",
    "dev_data_for_bert['label'] = dev_data_for_bert['label'].str.replace(\"cited\", \"entailment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert = train_data_for_bert.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "dev_data_for_bert = dev_data_for_bert.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert['index'] = train_data_for_bert.index\n",
    "dev_data_for_bert['index'] = dev_data_for_bert.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_bert.to_csv(\"../data/bert_train_1000.tsv\", index=False, sep='\\t', header=True)\n",
    "dev_data_for_bert.to_csv(\"../data/bert_dev_1000.tsv\", index=False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model.\n",
    "\n",
    "Use colab because of TPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a lightgbm model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/3b/4ae113193b4ee01387ed76d5eea32788aec0589df9ae7378a8b7443eaa8b/lightgbm-2.2.2-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |################################| 1.2MB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): scipy in /usr/local/lib/python3.5/dist-packages (from lightgbm)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy in /usr/local/lib/python3.5/dist-packages (from lightgbm)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-learn in /usr/local/lib/python3.5/dist-packages (from lightgbm)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.2\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/bert_train_1000.tsv\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"../data/bert_dev_1000.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claim_app</th>\n",
       "      <th>claim_cited_grant</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 . A process comprising the following steps:(...</td>\n",
       "      <td>1. A liquid supply apparatus, comprising:a wal...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 - 10 . (canceled) 11 . A method for open-loo...</td>\n",
       "      <td>1. A fuel supply apparatus for an engine, comp...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1 . A handpiece for treating biological tissue...</td>\n",
       "      <td>1. A method for irradiating tissue having abso...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 . A power cable comprising:a power input com...</td>\n",
       "      <td>1. A temperature regulating system for a vehic...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1 . A cutting insert having a substantially cu...</td>\n",
       "      <td>1. A toolholder comprising:a) a cutter body ro...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          claim_app  \\\n",
       "0      0  1 . A process comprising the following steps:(...   \n",
       "1      1  1 - 10 . (canceled) 11 . A method for open-loo...   \n",
       "2      2  1 . A handpiece for treating biological tissue...   \n",
       "3      3  1 . A power cable comprising:a power input com...   \n",
       "4      4  1 . A cutting insert having a substantially cu...   \n",
       "\n",
       "                                   claim_cited_grant           label  \n",
       "0  1. A liquid supply apparatus, comprising:a wal...  not_entailment  \n",
       "1  1. A fuel supply apparatus for an engine, comp...      entailment  \n",
       "2  1. A method for irradiating tissue having abso...      entailment  \n",
       "3  1. A temperature regulating system for a vehic...  not_entailment  \n",
       "4  1. A toolholder comprising:a) a cutter body ro...      entailment  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features by using TF-IDF vector.\n",
    "\n",
    "raw data will be made as: [claim_app] + [claim_cited_grant] (simple concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_claim_text = [\n",
    "    sentence_1 + sentence_2 \n",
    "    for sentence_1, sentence_2 \n",
    "    in zip(train_data['claim_app'], train_data['claim_cited_grant'])\n",
    "]\n",
    "\n",
    "\n",
    "test_claim_text = [\n",
    "    sentence_1 + sentence_2 \n",
    "    for sentence_1, sentence_2 \n",
    "    in zip(test_data['claim_app'], test_data['claim_cited_grant'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_x = vectorizer.fit_transform(train_claim_text)\n",
    "train_y = [ 1 if elem == 'entailment' else 0 for elem in train_data['label'] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2564, 17208)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 7.34 ms, total: 3.71 s\n",
      "Wall time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_x = vectorizer.transform(test_claim_text)\n",
    "test_y = [ 1 if elem == 'entailment' else 0 for elem in test_data['label'] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2502, 17208)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset for lightgbm and train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.2,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.683679\n",
      "[2]\ttraining's binary_logloss: 0.674582\n",
      "[3]\ttraining's binary_logloss: 0.666456\n",
      "[4]\ttraining's binary_logloss: 0.657978\n",
      "[5]\ttraining's binary_logloss: 0.65061\n",
      "[6]\ttraining's binary_logloss: 0.640629\n",
      "[7]\ttraining's binary_logloss: 0.63159\n",
      "[8]\ttraining's binary_logloss: 0.622584\n",
      "[9]\ttraining's binary_logloss: 0.614358\n",
      "[10]\ttraining's binary_logloss: 0.606217\n",
      "[11]\ttraining's binary_logloss: 0.598234\n",
      "[12]\ttraining's binary_logloss: 0.590287\n",
      "[13]\ttraining's binary_logloss: 0.582836\n",
      "[14]\ttraining's binary_logloss: 0.575774\n",
      "[15]\ttraining's binary_logloss: 0.56923\n",
      "[16]\ttraining's binary_logloss: 0.562423\n",
      "[17]\ttraining's binary_logloss: 0.555749\n",
      "[18]\ttraining's binary_logloss: 0.549391\n",
      "[19]\ttraining's binary_logloss: 0.542548\n",
      "[20]\ttraining's binary_logloss: 0.536594\n",
      "[21]\ttraining's binary_logloss: 0.531169\n",
      "[22]\ttraining's binary_logloss: 0.524756\n",
      "[23]\ttraining's binary_logloss: 0.518757\n",
      "[24]\ttraining's binary_logloss: 0.513114\n",
      "[25]\ttraining's binary_logloss: 0.508153\n",
      "[26]\ttraining's binary_logloss: 0.502165\n",
      "[27]\ttraining's binary_logloss: 0.496559\n",
      "[28]\ttraining's binary_logloss: 0.490382\n",
      "[29]\ttraining's binary_logloss: 0.485004\n",
      "[30]\ttraining's binary_logloss: 0.479735\n",
      "[31]\ttraining's binary_logloss: 0.474444\n",
      "[32]\ttraining's binary_logloss: 0.469659\n",
      "[33]\ttraining's binary_logloss: 0.464668\n",
      "[34]\ttraining's binary_logloss: 0.460135\n",
      "[35]\ttraining's binary_logloss: 0.455317\n",
      "[36]\ttraining's binary_logloss: 0.450112\n",
      "[37]\ttraining's binary_logloss: 0.445437\n",
      "[38]\ttraining's binary_logloss: 0.44059\n",
      "[39]\ttraining's binary_logloss: 0.436197\n",
      "[40]\ttraining's binary_logloss: 0.432309\n",
      "CPU times: user 6.23 s, sys: 148 ms, total: 6.38 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=40,\n",
    "                valid_sets=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = gbm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = [ 1 if elem >= 0.5 else 0 for elem in predict_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sum( np.array(predict_label) == np.array(test_y) ) / len(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6622701838529177\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows this problem is SOLVABLE (though accuracy is not so high)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
